---  
type: TutorialClass  
title: 0.3_Docker_Primer  
description: It is imperative you become acquainted with Docker and its commands  
  before we start the project. I needed to take a Udemy course! We will discuss  
  the vocab, common command routines, and project orchestration tools that come  
  with Docker. Much of our time will be spent in the command line during this  
  phase of the project. You will become an expert simply by repetition, I  
  promise!  
share: true  
category: 0_Getting_Started  
created: Tuesday, May 16th 2023, 2:34:08 pm  
modified: Thursday, June 8th 2023, 2:35:17 pm  
tags:  
  - docker  
  - docker-compose  
  - cli  
  - module-0  
status: in-progress  
---  
  
  
[â†Link to Previous Tutorial](./0.2_Development_with_VSCode.md#)  
  
---  
  
# 0.3_Docker_Primer  
  
---  
  
> âœ Note    
>I am a true believer in the power of this containerization platform and tool but I didnâ€™t start that way. I spent months of my life struggling to piece together tutorials and documentation for this project. I became a script-kitty and still couldnâ€™t fit the puzzle together.  
>  
>Finally, I took a Udemy course called [Docker & Kubernetes: The Practical Guide, 2023 Edition](https://www.udemy.com/share/103Ia0/). I cannot recommend the course enough (and no Iâ€™m not paid to say that!). I wonâ€™t be able to accomplish the same level of proficiency when developing this primer. If you can, find a tutorial like this one. It literally (rather figuratively) takes the witchcraft out of Docker.  
>  
>Much of this module section will be gleaned from my notes during this Udemy course. As such I have provided the course as a reference for this entire document (see the [Resources](0.3_Docker_Primer.md#resources) section).  
  
## Learning the Lingo  
  
Before I explain why you should be giddy about Docker, knowing a little of the lingo will help demystify the tool as a concept. There are many *Dockerisms* that need explaining but we must start with what a project built with Docker looks like.  
  
A Docker project is a standalone instance of code that can be run on any machine regardless if the computer itâ€™s running on has the needed programs or tools installed. Another computer need only Docker installed to run that code. This means, you can build an application on a Mac and pass it to a colleague running Windows or Linux (and vise versa) and it will run, without any additional configuration or translation, just the way it ran on original computer.  
  
This is all accomplished using the Docker Engine which provides a platform for images and containers to do their thing. There are two key concepts or building blocks to every docker instance : **images** and **containers** which are defined as follows :  
  
> ðŸŽ Definition    
> **Images** : A Docker image is a read-only blueprint for a service required by a given application or project i.e., a server, a database, or any tool that your project needs. An image (as opposed to a container) does not itself run. It is simply the scaffolding that defines a service: including its configuration, where it stores its data, which port/s it exposes, which network/s it uses, what credentials its has access to, etc.  
>  
> These elements are brought together using a `Dockerfile` which builds a layer for each command it contains. You can either use a pre-built image pulled from the [Docker Hub](https://hub.docker.com/) or define your own `Dockerfile` that appends to a base Docker Hub image.  
>  
> Whether built from *scratch* or not, every image is based on some Linux distribution, usually Ubuntu or Alpine. This forms the base layer whereupon each consecutive command is layered on top. As such, an image can be thought of as an onion of information describing *how* a service will operate while keeping track of where in its build process each piece of information was obtained. This will be important later when determining how we wish to order the commands in the `Dockerfile`.  
>  
> Based on this layering, an image is easily cacheable; only rebuilding layers that have been changed since it was last built. That makes the process of building and rebuilding images quicker and more efficient but also serves as a sort of time capsule that can be reverted to an older layer with a simple command. This can be dangerous if you have hardcoded sensitive data into the either the `Dockerfile` or any of the configuration files as they will be congealed into the layers for anyone to see.  
  
We will explore the various `Dockerfile` commands and their nuances in-depth when the time comes to build our own images but this high-level overview should get you through until then.  
  
> ðŸŽ Definition    
> **Containers** : Once an image has been built successfully, the service is ready to be *containerized* or run. Docker uses the imageâ€™s instructions to run an instance of a service and does so until it is stopped and/or removed. Whatever service is being run, be it an Apache server or a MariaDB database, a container built to the exact specifications of an image will do only what is prescribed to do. Nothing more nor less.  
>  
> Ideally each image and the container run from it are assigned a single task or mode. This is the convention for, not only, security purposes (minimizing the attack surface of a service) but also reducing the overall complexity of a single container.  
>  
> Once a container is stopped, the service stops. And once a container is removed any data that was being stored by the service is lost (though we can configure this not to be the case). Essentially, the container is ephemeral but unless specifically removed, the image will still exist and can still be run again without the need to rebuild it. This is convenient when you need to run multiple containers from a single image.  
  
As we delve deeper into the world of images and containers, I will continue drill these concepts into your brain because understanding their nature is half the battle.  
  
## Whatâ€™s The Deal with Docker?  
  
You may have heard about the buzz surrounding [Docker](https://www.docker.com/) in todayâ€™s tech industry but have you ever stopped to wonder why? There are many compelling reasons for its meteoric rise to nerd fandom, the most immediate being:  
  
- Like a virtual machine, Docker allows you to develop and package a project within a nifty container. The idea of a container of code comes in handy when sharing your project. It is basically a portable version of your project that can be run anywhere and achieve the same results.  
- Unlike a virtual machine, you can manage the size of the actual image  
---  
  
## Resources  
  
- ScwarzmÃ¼ller, M. (2023). Docker & Kubernetes: The Practical Guide [MOOC]. <https://www.udemy.com/share/103Ia0/>  
  
---  
  
[Link to Next Tutorial â†’](../1_Dockerize/1.0_The_Stack.md#)  
