---  
type: TutorialClass  
title: 0.3-Docker-Primer  
description: It is imperative you become acquainted with Docker and its commands  
  before we start the project. I needed to take a full Udemy course! We will  
  discuss the vocab, common command routines, and project orchestration tools  
  that come with Docker. Much of our time will be spent in the command line  
  during this phase of the project. You will become an expert simply by  
  repetition, I promise!  
share: true  
category: 0-Getting-Started  
created: Tuesday, May 16th 2023, 2:34:08 pm  
modified: Thursday, June 8th 2023, 9:57:01 pm  
tags:  
  - docker  
  - docker-compose  
  - cli  
  - module-0  
status: in-progress  
---  
  
  
[â†Link to Previous Tutorial](./0.2-Development-with-VSCode.md#)  
  
---  
  
# 0.3-Docker-Primer  
  
![](https://img.shields.io/badge/-Docker-2496ED?logo=docker&logoColor=white&style=plastic)  
  
---  
  
## Overview  
  
[Docker](https://www.docker.com/) is a one-stop shop for any project. Be it complex with lots of moving parts or a single service utility, Docker has enough flexibility and scalability to meet your needs. In this section, we will explore both the theory behind Docker containerization and actual implementation.  
  
We start with a  
  
> âš  Warning    
>Jumping into Docker without formal coursework is rough! I spent months of my life struggling to piece together tutorials and documentation for this project. I became a script-kitty and still couldnâ€™t fit the puzzle together.  
>  
>Finally, I took a Udemy course called [Docker & Kubernetes: The Practical Guide, 2023 Edition](https://www.udemy.com/share/103Ia0/). I cannot recommend the course enough (and no Iâ€™m not paid to say that!). Iâ€™ll tell you right now, I wonâ€™t be able to accomplish the same level of proficiency when developing this primer. If you can, find a tutorial like this one. It literally (rather figuratively) takes the witchcraft out of Docker.  
>  
>Much of this module section will be gleaned from my notes during this Udemy course. As such I have provided the course as a reference for this entire document (see the [Resources](0.3-Docker-Primer.md#resources) section).  
  
## Learning the Lingo  
  
Before I explain why you should be giddy about Docker, knowing a little of the lingo will help demystify the tool as a concept. There are many *Dockerisms* that need explaining but we must start with what a project built with Docker looks like.  
  
A Docker project is a standalone instance of code that can be run on any machine regardless if the computer itâ€™s running on has the needed programs or tools installed. Another computer need only Docker installed to run that code. This means, you can build an application on a Mac and pass it to a colleague running Windows or Linux (and vise versa) and it will run, without any additional configuration or translation, just the way it ran on original computer.  
  
This is all accomplished using the Docker Engine which provides a platform for images and containers to do their thing. There are two key concepts or building blocks to every docker instance : **images** and **containers** which are defined as follows :  
  
> ðŸŽ Definition    
> **Images** : A Docker image is a read-only blueprint for a service required by a given application or project i.e., a server, a database, or any tool that your project needs. An image (as opposed to a container) does not itself run. It is simply the scaffolding that defines a service: including its configuration, where it stores its data, which port/s it exposes, which network/s it uses, what credentials its has access to, etc.  
>  
> These elements are brought together using a `Dockerfile` which builds a layer for each command it contains. You can either use a pre-built image pulled from the [Docker Hub](https://hub.docker.com/) or define your own `Dockerfile` that appends to a base Docker Hub image.  
>  
> Whether built from *scratch* or not, every image is based on some Linux distribution, usually Ubuntu or Alpine. This forms the base layer whereupon each consecutive command is layered on top. As such, an image can be thought of as an onion of information describing *how* a service will operate while keeping track of where in its build process each piece of information was obtained. This will be important later when determining how we wish to order the commands in the `Dockerfile`.  
>  
> Based on this layering, an image is easily cacheable; only rebuilding layers that have been changed since it was last built. That makes the process of building and rebuilding images quicker and more efficient but also serves as a sort of time capsule that can be reverted to an older layer with a simple command. This can be dangerous if you have hardcoded sensitive data into the either the `Dockerfile` or any of the configuration files as they will be congealed into the layers for anyone to see.  
  
We will explore the various `Dockerfile` commands and their nuances in-depth when the time comes to build our own images but this high-level overview should get you through until then.  
  
> ðŸŽ Definition    
> **Containers** : Once an image has been built successfully, the service is ready to be *containerized* or run. Docker uses the imageâ€™s instructions to run an instance of a service and does so in isolation until it is stopped and/or removed. Whatever service is being run, be it an Apache server or a MariaDB database, a container built to the exact specifications of an image will do only what is prescribed to do. It will not share state or data with any other container or service.  
>  
> Ideally each image and the container run from it are assigned a single task or mode. This is the convention for, not only, security purposes (minimizing the attack surface of a service) but also reducing the overall complexity of a single container.  
>  
> Once a container is stopped, the service stops. And once a container is removed any data that was being stored by the service is lost (though we can configure this not to be the case). Essentially, the container is ephemeral but unless specifically removed, the image will still exist and can still be run again without the need to rebuild it. This is convenient when you need to run multiple containers from a single image.  
  
As we delve deeper into the world of images and containers, I will continue drill these concepts into your brain because understanding their nature is half the battle.  
  
## Whatâ€™s The Deal with Docker?  
  
You may have heard about the buzz surrounding Docker in todayâ€™s tech industry but have you ever stopped to wonder why? There are many compelling reasons for its meteoric rise to nerd fandom, the most immediate being:  
  
- The most obvious reason for Dockerâ€™s success is that you donâ€™t need to install any programs (besides the Docker engine itself) on your **host computer**. You can also spin up a quick *utility container* to generate SSL certificates/keys or run a `Node.js` server to test a website idea on the fly.  
- Like a **virtual machine**, Docker allows you to develop and package a project within a nifty container. The idea of a container of code comes in handy when sharing your project. It is basically a portable version of your project that can be run anywhere and still achieve the same results.  
- Unlike a virtual machine, you can manage the size of the actual image granularly by using an [Alpine Linux](https://www.alpinelinux.org/) base image, this OS is super light weight because itâ€™s not bloated with unnecessary installs. You can also limit the image footprint with a carefully configured `Dockerfile` and by keeping each image/container confined to a singular task.  
- Docker is also known to be great for all stages of a project, from development to production because of its scalability and integration with [Kubernetes](https://www.docker.com/products/kubernetes/), a mass container orchestration tool.  
- Docker can also be used to implement a high degree of security with its built-in [Docker Secrets](https://docs.docker.com/engine/swarm/secrets/) tool that can be used to encrypt and distribute credentials, SSL certificates, and other sensitive information to the specific containers that require them without hardcoding them into the containers themselves.  
  
> ðŸŒŽ The Big Picture    
>Now that we know why Docker rocks, letâ€™s start considering how to take these abstract concepts from theory to practice. Weâ€™ll start small with some example images and containers to get the command routines down, a little muscle memory will help when we actually start building the project out.  
  
## Installing the Docker Engine on Your Host Machine  
  
This will likely be the last installation you need to make on your host machine.  
  
## A Typical Docker Project Pipeline  
  
---  
  
## Resources  
  
- ScwarzmÃ¼ller, M. (2023). Docker & Kubernetes: The Practical Guide [MOOC]. <https://www.udemy.com/share/103Ia0/>  
  
---  
  
[Link to Next Tutorial â†’](1.0-The-Stack.md#)  
