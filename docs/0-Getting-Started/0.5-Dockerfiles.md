---  
type: TutorialClass  
title: 0.5-Dockerfiles  
description: We will go over Dockerfile syntax and instruction types. We will  
  end with a discussion on Multistage builds and other ways to make our custom  
  images more efficient and slender.  
share: true  
module: 0-Getting-Started  
created: Thursday, July 6th 2023, 6:49:18 pm  
modified: Monday, July 10th 2023, 8:07:20 am  
tags:  
  - shapecreations  
  - docker  
  - dockerfile  
  - image  
  - build  
media: ""  
status: complete  
---  
  
  
# 0.5-Dockerfiles  
  
![](https://img.shields.io/badge/-Docker-2496ED?logo=docker&logoColor=white&style=plastic)  
  
---  
  
## Overview  
  
> ðŸŽ Definition    
> A Dockerfile is a text file that contains all the commands and information necessary to build an image.  
  
Since we will need custom configurations for all of our images, we will be using [Dockerfiles](https://docs.docker.com/engine/reference/builder/#:~:text=Docker%20can%20build%20images%20automatically,can%20use%20in%20a%20Dockerfile%20.). Any Docker image found on the [Docker Hub](https://hub.docker.com/) uses a `dockerfile` to implement startup images. This can include installing built in programs, copying over external configuration files, setting a working directory, permissions, etc. We will be learning the syntax for such a file and configuring our images upfront in this way.  
  
> ðŸ”¦ Flashback    
> If you recall from [Module 1 - Section 03](./0.3-Docker-Primer.md#learning-the-lingo) images are made up of read-only layers that we then run a container from. As such, everything that goes in the `Dockerfile` will become embedded in these read-only layers.  
  
The result of these dockerfiles will be a custom configured image with all of the programs and configuration baked-in. We will also copy over the files from the project itself so certain containers have access to our live code but more on this later.  
  
Within a Dockerfile, there are several instruction types that can be used to do anything from run CLI programs, install programs, switch users, copy files from the host to the image, set the runtime command, and more! Before we take a look at our first Dockerfile, we will explore some best use practices and instruction types that you should become familiar with before commencing the project.  
  
The instruction types we will cover in this section and use throughout the project are as listed (in order of appearance):  
  
- [FROM](0.5-Dockerfiles.md#the-from-instruction)  
- [WORKDIR](0.5-Dockerfiles.md#the-workdir-instruction)  
- [ENV](0.5-Dockerfiles.md#env)  
- [ARG](0.5-Dockerfiles.md#arg)  
- [RUN](0.5-Dockerfiles.md#the-run-instruction)  
- [ADD](0.5-Dockerfiles.md#add)  
- [COPY](0.5-Dockerfiles.md#copy)  
- [VOLUME](0.5-Dockerfiles.md#volume)  
- [USER](0.5-Dockerfiles.md#the-user-instruction)  
- [EXPOSE](0.5-Dockerfiles.md#the-expose-instruction)  
- [CMD](0.5-Dockerfiles.md#cmd)  
- [ENTRYPOINT](0.5-Dockerfiles.md#entrypoint)  
  
> âœ Note    
> We will only cover the basic usages of these commands, for a complete reference, check out the [Docker - Dockerfile Reference](https://docs.docker.com/engine/reference/builder/). Much of the information shared in this section comes directly from this resource anyways.  
  
## General Rules  
  
Docker syntax is quite simple at its core. Comments are denoted with a `#` symbol and each command must be on its own line. While not required, all instructions are typically written using ALL CAPS.  
  
```Dockerfile  
# This is a comment  
FROM apache  
```  
  
Since we are writing the instructions to build a nicely packaged Docker image. Instructions are built in order and a few of the instructions themselves denote new layers including: .  
  
### Cached Layers  
  
There are some considerations to be had when deciding when and where we put certain instructions. This is because when we build our images, a cache helps keep track of what has changed from the present build to the previous, then only building layers that have changed starting from the first change.  
  
In practice, this means putting instructions that copy code subject to change near the end and lengthy installations near the beginning so that we donâ€™t have to rebuild installation layers each time a configuration file is changed.  
  
> ðŸ”’ Security    
> Remember, each layer in an image can be inspected with `docker history`! Our layers should not contain any secrets or otherwise sensitive information. We will discuss how to get around this [soon](./0.6-Docker-Compose.md#the-secrets-attribute).  
  
### Naming the File  
  
Dockerfiles are usually named `dockerfile` (or some version of that). This helps, especially for VS Code to help auto suggestions. We will be using the `{service_name}.dockerfile` convention in our project as VS Code recognizes it.  
  
> ðŸ”® Crystal Ball    
 > We want VS Code to recognize these files because it will help us select valid base image variants and versions as well as help with syntax.  
  
### The `FROM` Instruction  
  
Every Dockerfile needs a `FROM...` instruction at the beginning of the file. This is like the `docker pull` command on the CLI. In general, you can use any base image from the Docker Hub, but there are often variants and specific versions that can be specified.  
  
> âœ Note    
> It is good practice to specify both of these things in our Dockerfiles as it will protect us from unforeseen differences between versions that can break our builds.  
  
Dockerfiles can be as simple as a `FROM` instruction but if this is all you need, you may as well build your image from the CLI. Nothing can precede a `FROM` instruction except comments or `ARG` instructions.  
  
### The `WORKDIR` Instruction  
  
The `WORKDIR` instruction is used to set the working directory for use by the other Dockerfile instructions including: `RUN`, `CMD`, `ENTRYPOINT`, `COPY`, and `ADD`. This instruction greatly improves readability and maintains an active scope to keep things in the image straight. It may be used several times throughout the Dockerfile when creating complex file systems that will later be used by the containers run from the image.  
  
Here is a simple use case for the `WORKDIR` instruction using a simple `COPY` statement that copies a folder called `app/` in the current host directory to the working directory:  
  
```Dockerfile  
WORKDIR /path/to/working/directory  
  
COPY ./app .  
```  
  
> âœ Note    
> Throughout our time with Docker, we will often use the `.` notation to refer to the current directory. This can be done to reduce relative paths as in `./app` which refers to a folder named `app/` within the current working directory of the host computer and `.` which refers to the current working directory denoted by the `WORKDIR` instruction.  
  
### Variable Replacement: The `ENV` & `ARG` Instructions  
  
So I mentioned before that there are some exceptions to the layer per instruction rule. Two of those exceptions are the `ARG` and `ENV` instructions. These instructions are used to pass variables into our image build. We will discuss each individually as they should be used for two distinct purposes. Their shared purpose though is to prevent having to hardcode values that might otherwise be different for different image builds (e.g., development vs. production).  
  
#### `ENV`  
  
The `ENV` instruction is used to replace values both during the image build and during container runtime. This means, `ENV` values can be accessed by the containers after an image is built using the Dockerfile.  
  
There are a number of ways we can set `ENV` variables. There is an order of precedence too that allows certain methods to override others. That order goes as follows (highest to lowest) (Docker, 2023a).:  
  
1. Using the `-e` flag in a `docker compose -e` in the CLI.  
2. Substituted from your shell variables.  
3. Set using the `environment` attribute in the `docker-compose.yml` file.  
4. Use of theÂ `--env-file`Â argument in the CLI  
5. Use of theÂ `env_file`Â attributeÂ in the Compose file  
6. Set using anÂ `.env`Â fileÂ placed at base of your project directory  
7. Set in a container image in theÂ `ENV` directive. Having anyÂ `ARG`Â orÂ `ENV`Â setting in aÂ `Dockerfile`Â evaluates only if there is no Docker Compose entry forÂ `environment`,Â `env_file`Â orÂ `run --env`.  
  
We will only consider a select few of these methods as most are not applicable within the scope of this project. When defining an `ENV` variable within the Dockerfile, the `ENV` key is often named using ALL CAPS and the syntax for `ENV` variables is as such:  
  
```Dockerfile  
ENV KEY=value  
  
RUN some_command ${KEY}  
```  
  
> ðŸ”® Crystal Ball    
> We will learn the syntax for defining `ENV` variables as a Docker Compose attribute in the next section.  
  
Once set in the Dockerfile, `ENV` values cannot be overridden from the command line at build time. They can however be changed after container runtime which can be useful if you wish to have a different value parsed in the container than what was used in the image itself. A common use for this is when you want to run different containers using the same image.  
  
You would very generally use `ENV` variables to pass credentials, certificates, secrets, and other sensitive information to the containers that require them.  
  
> ðŸ”’ Security    
> We will not use `ENV` variables *directly* to send sensitive information to our containers. Instead, we will use a neat service provided by Docker called [Docker Secrets](https://docs.docker.com/engine/swarm/secrets/) (more on this later).  
  
#### `ARG`  
  
The `ARG` instruction is used to pass variables at build time, which means they are only available within the scope of the image, not the container. Usually `ARG` variables are used when the container is not interested in the value or when you need to set a value dynamically at build time.  
  
There are far fewer ways to define an `ARG` variable than for `ENV` variables. Also note that given the same key name, an `ENV` variable will override the value set for the `ARG` variable.  
  
1. Defined at the CLI using `--build-arg` .  
2. Given a default value within a Dockerfile.  
3. Set using the `arg` attribute nested under the `build` attribute of a `docker-compose.yml` file service.  
  
> âš  Warning!    
> If an `ARG` variable is used in a Dockerfile but is not defined by one of these methods, a warning will be thrown at build time.  
  
The syntax for `ARG` instructions within a Dockerfile is identical to that of `ENV` instructions:  
  
```Dockerfile  
ARG KEY=value  
  
RUN some_command ${KEY}  
```  
  
> ðŸ”® Crystal Ball    
> It goes without saying that we will cover the Docker Compose syntax in the next section.  
  
> ðŸ”’ Security    
> `ARG` instructions are *not* a good way to pass secrets, credentials, or other sensitive material to the image! Values passed this are visible to any user with the `docker history` command.  
  
> ðŸ”¦ Flashback    
> As mentioned in the `FROM` instruction heading, the `ARG` instruction is the only instruction that can precede it and the `ARG` itself must only be referenced in that `FROM` instruction, as for, the variant or version number. For example:  
>  
> ```Dockerfile  
> ARG VERSION=2.4.57  
> FROM httpd:${VERSION}  
> ```  
>  
> However, any `ARG` variables set above the `FROM` instruction must be re-declared below it to be made usable to the rest of the build.  
  
Something unique to `ARG` variables is that they can be set from the CLI using `--build-arg {ARGUMENT_VARIABLE}`. `ENV` variables cannot be dynamically changed in this way. This can be done as follows:  
  
```shell  
$ docker build --build-arg VARIABLE=value .  
```  
  
Common use cases for `ARG` variables are version numbers and tags for the base image and when setting a non-root user. We have also elected to use them to simplify host path names that are subject to change as our project directory evolves.  
  
> ðŸ”® Crystal Ball    
> In a rather unconventional way, we will be using a universal `.env` file to set our `ARG` variables using Docker Compose. This is not necessarily how our final project will handle `ARG` variables but it works and prevents the need to hardcode repetitive values into each Dockerfile.  
>  
> Security considerations on this are inconclusive at the time this Module has been written... We may implement an `build.sh` in the future to pass all `ARG` variables at the CLI to prevent their hardcoding into the container through the `.env` file.  
  
### The `RUN` Instruction  
  
The `RUN` instruction is one of the most dynamic in the Dockerfile arsenal. Despite its power, it is relatively simple to explain. Use `RUN` to execute any shell program or command inside the image file space.  
  
The `RUN` instruction can take one of two forms:  
  
1. The *shell* form: `RUN <command> ` which should be used whenever executing a command via the `bin/sh -c` shell.  
2. The *exec* form: `RUN ["exectuable", "param1", "param2"]` which can be used to run a command from another shell by setting the `SHELL` instruction. We wonâ€™t use this form.  
  
Here is a simple example of using `RUN` to upgrade and update an ubuntu image:  
  
```Dockerfile  
FROM ubuntu:latest  
  
RUN apt-get update \  
	&& apt-get upgrade  
```  
  
> âœ Note    
> Notice in the above example the `\` symbol is being used to separate multiple commands onto different lines. This is best practice as it helps to make code more readable. Consider also, alphabetizing commands listed in this manner to ease in program installations and such.  
  
> ðŸŒŽ The Big Picture    
> `RUN` is one of the commands that generates a new layer. Upon reaching a `RUN` instruction, a new read-only layer is added to the top of the current image.  
  
### The `ADD`, `COPY` & `VOLUME` Instructions  
  
There will be several files needed to be shared between our host computer and docker container; not least of which is the application folder itself! There are several options to do so but they are not necessarily interchangeable: (1) `ADD`, (2) `COPY`, and (3) `VOLUME`. Each comes with its own pros and cons, as well as special functionalities that make them preferable to the others for certain types of files.  
  
> ðŸ”’ Security    
> Pay attention to best use cases for each of these *file sharing* instructions, often our biggest consideration when deciding between the three is whether or not we want to obfuscate or persist data (even when a container is stopped!).  
  
#### `ADD`  
  
The `ADD` instruction can be used to add new files, directories, or remote file URLs to a destination within the image file system. Though it was the standard in the early days of Docker, it has since been replaced with the `COPY` instruction.  
  
> ðŸ”’ Security    
> This instruction is outdated and unpredictable, Docker even advises against using it in its [Best Practices](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#:~:text=COPY%20only%20supports%20the%20basic,rootfs.tar.xz%20%2F%20.) documentation. It is also incapable of handling remote files using secure protocols. These types of adds are best left to `RUN wget` or `RUN curl` instructions.  
  
#### `COPY`  
  
The programmers at Docker designed the `COPY` instruction to replace the local file copying functionality of the `ADD` instruction. It is more reliable and simplistic but it does its job. It is used to make local files available within the image file system, i.e., configuration files, code, etc.  
  
The `COPY` instruction currently takes two forms both with optional commands to set permissions. This greatly improves functionality when using the `USER` instruction and granting this new user permissions on added files.  
  
- `COPY [--chown=USER:GROUP] [--chmod=permissions] <source> <destination>`  
- `COPY [--chown=USER:GROUP] [--chmod=permissions] ["source",... "destination"]'  
  
#### `VOLUME`  
  
Before we get to the `VOLUME` instruction, Volumes deserve a bit more of an explanation as they are a major concept in Docker at large. Volumes allow you to share files between the host and the image file system and *persist* even if you stop the container!  
  
> âš  Warning!    
> Data does not naturally persist in a container. It only exists so long as a container is running; once a container is stopped, the data is lost. If you want data within a container to persist, you must use either volumes or a bind mount. Bind mounts wonâ€™t be discussed in this tutorial.  
  
There are two types of volumes, each with their own use cases. The main thing to remember is that with a volume, there is a link between some folder on the host computer and a folder within the container. When declaring a volume, the connection is initialized within the image build step but does not become active until container runtime to maintain portability.  
  
- *Anonymous* volumes store data from the container somewhere in the host filesystem. Where is not important and is unnecessary if you just wish for data to persist between container stops. Once you remove the container, it is lost but still exists somewhere in the file system. You can use a `-rm` flag in the `docker run` command when at the CLI to automatically remove these volumes or you can manually remove them using the `docker volume prune` command.  
- *Named* volumes are different in that the location of the data on the host file system is known and defined by the user. This is useful if you want to share changes to files back and forth between the host and container. Data shared in this way updates live; as changes are made in the local folder or the container folder, they are reflected in the other. This is how we will connect our source code to the container as we wouldnâ€™t want to have to constantly have to rebuild our image every time we make an update. These types of volumes are not removed automatically as it would be dangerous if Docker was able to delete files from your computer.  
  
When declaring a volume in an image you can do it a number of ways:  
  
| Volume Type           | Anonymous                           | Named                                        |  
| --------------------- | ----------------------------------- | -------------------------------------------- |  
| From the CLI          | `docker run -v <destination> IMAGE` | `docker run -v <source>:<destination> IMAGE` |  
| Within the Dockerfile | `VOLUME ["/data"]`                  | `VOLUME ["/host/data":"/container/data"]`    |  
| Using Docker Compose  | Use the `volumes` attribute.          | Use the `volumes` attribute.                                             |  
  
> ðŸ”® Crystal Ball    
> We will opt for the Docker Compose option as we wish to have separate image builds for development and production. This concept as well as other project design principles will be discussed at length in the next Module.  
  
### The `USER` Instruction  
  
By default, Docker containers are run (and images are built) as root user. It isnâ€™t obvious why at first, as this sounds like a major security concern. But especially in the build phase, the image user needs to have permission to install commands, make directories, etc. So it makes sense to use root during these steps. However, this should not be the case in our running container.  
  
Thankfully, we can change the user in the latter parts of our build that continues when running the container. We do this using the `USER` instruction, which has two forms:  
  
- `USER <user>[:<group>]`  
- `USER <uid>[:<gid>]`  
  
Before we can assign a user we must first create the new user (and group) with `RUN addgroup...` and `RUN adduser...` instructions. We must also grant permissions to the files, folders, commands, etc. that we wish the user to have access too. We do this using `RUN chown <user>:<group> /path` instructions. The order in which we issue Dockerfile instructions is very dependent on these processes.  
  
### The `EXPOSE` Instruction  
  
Mainly a formality, the `EXPOSE` instruction documents which port/s are exposed in the eventual container. Adding this to your Dockerfile is not necessary but it is good practice. It has simple syntax: `EXPOSE <port>` and you can list multiple ports.  
  
### The `CMD` & `ENTRYPOINT` Instructions  
  
The `CMD` & `ENTRYPOINT` instructions are oddballs when compared to the other Dockerfile instructions. First and foremost, they are not a build time instructions like all the others; they are runtime commands that define the default behavior of the `docker run` command.  
  
#### `CMD`  
  
`CMD` is used to set a default run command that will execute once a container is started from that particular image (or omit the default run command). A `CMD` instruction can also be overridden during the `docker run` command and will be replaced by whatever is entered at the CLI. `CMD` should be used if your container may be run in interactive mode or will otherwise be run in varying ways.  
  
It can take three forms:  
  
- The preferred form is the *exec* form: `CMD ["executable", "param1", "param2"]`  
- As a default for the `ENTRYPOINT` instruction: `CMD ["param1", "param2"]`  
- The *shell* form in which the `SHELL` instruction should be used to define the desired shell: `CMD executable param1 param2`  
  
There can only be one `CMD` instruction in a given Dockerfile (any duplicates will result only in the last being valid). And it is convention that this instruction be declared at the end of the Dockerfile.  
  
#### `ENTRYPOINT`  
  
Much like the `CMD` instruction, the `ENTRYPOINT` instruction also defines the default command that will be executed once a container is run. By contrast though, the `ENTRYPOINT` instruction cannot be overridden by commands or parameters passed in the `docker run` command. This is why, when possible, `ENTRYPOINT` should be used over `CMD`. Always use `ENTRYPOINT` when you need your container to be run as an executable!  
  
`ENTRYPOINT` can be invoked two ways:  
  
- The preferred form is the *exec* form: `ENTRYPOINT ["executable", "param1", "param2"]`  
- The *shell* form in which the `SHELL` instruction should be used to define the desired shell: `ENTRYPOINT executable param1 param2`  
  
> âœ Note    
> If need be, `ENTRYPOINT` can be replaced at the CLI using the `--entrypoint` flag when starting up a container.  
  
#### Using `CMD` & `ENTRYPOINT` Together  
  
It was alluded to earlier in this section, but there are some use cases where it is beneficial to use both `CMD` and `ENTRYPOINT` together. We might choose to do so if we have a container that we wish to only be used for a certain command but that might have different or additional parameters passed at run time.  
  
Here is the Dockerfile syntax and the proceeding Docker command for a simple container named `greeting-container` that prints `Hello <name>`. The default command is given by `ENTRYPOINT`, default parameter is given by `CMD` instruction, and if desired, a different parameter may be passed through the `docker run` command to replace that default given by `CMD`:  
  
```Dockerfile  
FROM ubuntu  
ENTRYPOINT ["echo", "Hello"]  
CMD ["Ms. Nyki"]  
```  
  
If we run Version 1 of the command, we get the output `Hello Ms. Nyki`. Version 2 will print out the alternative message of `Hello Ms. Anderson`.  
  
```shell  
# Version 1  
$ docker run greeting-container  
  
# Version 2  
$ docker run greeting-container "Ms. Anderson"  
```  
  
> âœ Note    
> When using the two instructions together, be sure to use the `exec` form of both.  
  
## Advanced Topics  
  
Two of the biggest concerns when designing Dockerfiles are build time and image size.   
  
---  
  
## References  
  
Docker. (2023a, July 8).Â *Environment variables precedence*. Docker Documentation. <https://docs.docker.com/compose/environment-variables/envvars-precedence/>  
  
Docker. (2023b, July 8).Â *Share Compose configurations between files and projects*. Docker Documentation. <https://docs.docker.com/compose/extends/#adding-and-overriding-configuration>  
  
ScwarzmÃ¼ller, M. (2023). Docker & Kubernetes: The Practical Guide [MOOC]. Section 5: Building Multi-Container Applications with Docker. Udemy. <https://www.udemy.com/share/103Ia03@NIeuWLCBpXz9Asqz04rkP-_CNSQIKXErlgRJiOPMlNKtC0p-elHO_4KXZAlK3wo=/>Â   
  
Simic, S. (2019, December 16).Â *Docker ADD vs COPY: What is the Difference and Which One to Use?*Â Knowledge Base by PhoenixNAP. <https://phoenixnap.com/kb/docker-add-vs-copy>  
